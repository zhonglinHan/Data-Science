{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "df_train = pd.read_csv('../input/train_users_2.csv')\n",
    "df_test = pd.read_csv('../input/test_users.csv')\n",
    "labels = df_train['country_destination'].values\n",
    "df_train = df_train.drop(['country_destination'], axis=1)\n",
    "id_test = df_test['id']\n",
    "piv_train = df_train.shape[0]\n",
    "\n",
    "#Creating a DataFrame with train+test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "#Removing id and date_first_booking\n",
    "df_all = df_all.drop(['id', 'date_first_booking'], axis=1)\n",
    "#Filling nan\n",
    "df_all = df_all.fillna(-1)\n",
    "\n",
    "#####Feature engineering#######\n",
    "#date_account_created\n",
    "dac = np.vstack(df_all.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "df_all['dac_year'] = dac[:,0]\n",
    "df_all['dac_month'] = dac[:,1]\n",
    "df_all['dac_day'] = dac[:,2]\n",
    "df_all = df_all.drop(['date_account_created'], axis=1)\n",
    "\n",
    "#timestamp_first_active\n",
    "tfa = np.vstack(df_all.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)\n",
    "df_all['tfa_year'] = tfa[:,0]\n",
    "df_all['tfa_month'] = tfa[:,1]\n",
    "df_all['tfa_day'] = tfa[:,2]\n",
    "df_all = df_all.drop(['timestamp_first_active'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Age\n",
    "av = df_all.age.values\n",
    "df_all['age'] = np.where(np.logical_or(av<14, av>100), -1, av)\n",
    "\n",
    "#One-hot-encoding features\n",
    "ohe_feats = ['gender', 'signup_method', 'signup_flow', 'language', \n",
    "             'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', \n",
    "             'first_device_type', 'first_browser']\n",
    "for f in ohe_feats:\n",
    "    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n",
    "    df_all = df_all.drop([f], axis=1)\n",
    "    df_all = pd.concat((df_all, df_all_dummy), axis=1)\n",
    "\n",
    "#Splitting train and test\n",
    "vals = df_all.values\n",
    "X = vals[:piv_train]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)   \n",
    "X_test = vals[piv_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifier\n",
    "xgb = XGBClassifier(max_depth= 6, learning_rate=0.1, n_estimators=100,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \n",
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = xgb.predict_proba(X_test)  \n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "\n",
    "#Generate submission\n",
    "sub_xgb = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub_xgb.to_csv('../output/sub_xgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0001, n_estimators=500, n_jobs=8,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "rfclf = RF(n_estimators= 500, n_jobs = 8, class_weight = 'balanced', \n",
    "           min_samples_split = 20, min_weight_fraction_leaf =0.0001,\n",
    "           verbose = 0)\n",
    "\n",
    "# train the model on the data\n",
    "rfclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rfclf.predict_proba(X_test)  \n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "\n",
    "#Generate submission\n",
    "sub_rf = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub_rf.to_csv('../output/sub_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic  Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logclf = linear_model.LogisticRegression(dual = False,\n",
    "                                       C = 10.0, class_weight = 'balanced', \n",
    "                                       solver = 'sag')\n",
    "logclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logclf.predict_proba(X_test)  \n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 1\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:1].tolist()\n",
    "\n",
    "#Generate submission\n",
    "sub_lg = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub_lg.to_csv('../output/sub_lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtl0dijy2j</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx0ulgorjt</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6puo6ix0</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>czqhjk3yfe</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>szx28ujmhf</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guenkfjcbq</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tkpq0mlugk</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3xtgd5p9dn</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>md9aj22l5a</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gg3eswjxdf</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fyomoivygn</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iq4kkd5oan</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6k1xls6x5j</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jodmb2ok1f</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eq6fy0m4vc</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yq4i7nfh6l</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>q5pibqdous</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i0sc6d3j8s</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>br5mcrsqzn</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rddbczuxx1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>glck7hlmzz</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sxpkaxep8n</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sr4ntmalz2</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>f6wueq1ccn</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ovc6nwn6mj</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n10skstp90</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5jrbdigmv4</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>d45nngmojp</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>y0frb6t1kq</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62066</th>\n",
       "      <td>bsv2ev628t</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62067</th>\n",
       "      <td>06echc56pl</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62068</th>\n",
       "      <td>niqgaye2ov</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62069</th>\n",
       "      <td>61iwzuhw6e</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62070</th>\n",
       "      <td>gks02el96u</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62071</th>\n",
       "      <td>v4r1161l0r</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62072</th>\n",
       "      <td>p1clbqd0o6</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62073</th>\n",
       "      <td>ozb2z0km6l</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62074</th>\n",
       "      <td>w3e3sp6i70</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62075</th>\n",
       "      <td>q5bxbq0asg</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62076</th>\n",
       "      <td>1xa5t3t0la</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62077</th>\n",
       "      <td>zuvz7gfpjz</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62078</th>\n",
       "      <td>gpusl6ppgf</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62079</th>\n",
       "      <td>gpijioh4eh</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62080</th>\n",
       "      <td>3ptlvdxss9</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62081</th>\n",
       "      <td>f9a1ncjnrg</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62082</th>\n",
       "      <td>kofaz2kh70</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62083</th>\n",
       "      <td>6xrmom7hjo</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62084</th>\n",
       "      <td>cg9wqgnad2</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62085</th>\n",
       "      <td>jg618z94wo</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62086</th>\n",
       "      <td>u7lv3glv6y</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62087</th>\n",
       "      <td>o6ofmozucx</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62088</th>\n",
       "      <td>wcw7xggeqp</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62089</th>\n",
       "      <td>m22pw2pkxr</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62090</th>\n",
       "      <td>8yvhec201j</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62091</th>\n",
       "      <td>cv0na2lf5a</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62092</th>\n",
       "      <td>zp8xfonng8</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62093</th>\n",
       "      <td>fa6260ziny</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62094</th>\n",
       "      <td>87k0fy4ugm</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62095</th>\n",
       "      <td>9uqfg8txu3</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62096 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id country\n",
       "0      5uwns89zht      PT\n",
       "1      jtl0dijy2j      PT\n",
       "2      xx0ulgorjt      PT\n",
       "3      6c6puo6ix0      PT\n",
       "4      czqhjk3yfe      PT\n",
       "5      szx28ujmhf      PT\n",
       "6      guenkfjcbq      PT\n",
       "7      tkpq0mlugk      PT\n",
       "8      3xtgd5p9dn      PT\n",
       "9      md9aj22l5a      PT\n",
       "10     gg3eswjxdf      PT\n",
       "11     fyomoivygn      PT\n",
       "12     iq4kkd5oan      PT\n",
       "13     6k1xls6x5j      PT\n",
       "14     jodmb2ok1f      PT\n",
       "15     eq6fy0m4vc      PT\n",
       "16     yq4i7nfh6l      PT\n",
       "17     q5pibqdous      PT\n",
       "18     i0sc6d3j8s      PT\n",
       "19     br5mcrsqzn      PT\n",
       "20     rddbczuxx1      PT\n",
       "21     glck7hlmzz      PT\n",
       "22     sxpkaxep8n      PT\n",
       "23     sr4ntmalz2      PT\n",
       "24     f6wueq1ccn      PT\n",
       "25     ovc6nwn6mj      PT\n",
       "26     n10skstp90      PT\n",
       "27     5jrbdigmv4      PT\n",
       "28     d45nngmojp      PT\n",
       "29     y0frb6t1kq      PT\n",
       "...           ...     ...\n",
       "62066  bsv2ev628t      PT\n",
       "62067  06echc56pl      PT\n",
       "62068  niqgaye2ov      PT\n",
       "62069  61iwzuhw6e      PT\n",
       "62070  gks02el96u      PT\n",
       "62071  v4r1161l0r      PT\n",
       "62072  p1clbqd0o6      PT\n",
       "62073  ozb2z0km6l      PT\n",
       "62074  w3e3sp6i70      PT\n",
       "62075  q5bxbq0asg      PT\n",
       "62076  1xa5t3t0la      PT\n",
       "62077  zuvz7gfpjz      PT\n",
       "62078  gpusl6ppgf      PT\n",
       "62079  gpijioh4eh      PT\n",
       "62080  3ptlvdxss9      PT\n",
       "62081  f9a1ncjnrg      PT\n",
       "62082  kofaz2kh70      PT\n",
       "62083  6xrmom7hjo      PT\n",
       "62084  cg9wqgnad2      PT\n",
       "62085  jg618z94wo      PT\n",
       "62086  u7lv3glv6y      PT\n",
       "62087  o6ofmozucx      PT\n",
       "62088  wcw7xggeqp      PT\n",
       "62089  m22pw2pkxr      PT\n",
       "62090  8yvhec201j      PT\n",
       "62091  cv0na2lf5a      PT\n",
       "62092  zp8xfonng8      PT\n",
       "62093  fa6260ziny      PT\n",
       "62094  87k0fy4ugm      PT\n",
       "62095  9uqfg8txu3      PT\n",
       "\n",
       "[62096 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "linearclf = linear_model.LinearRegression()\n",
    "linearclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-40cd8add90ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinearclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Taking the 5 classes with highest probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#list of ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#list of countries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "y_pred = linearclf.predict_proba(X_test)  \n",
    "\n",
    "#Taking the 5 classes with highest probabilities\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "\n",
    "#Generate submission\n",
    "sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub.to_csv('../output/sub_lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
